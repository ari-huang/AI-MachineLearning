{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-108403201.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4402104-ace1-4819-d405-27791c293649"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "# 太多人同時存取可能會報cannot retrieve file error\n",
        "# 點擊you may still be able to access 下面那個連結再自行上傳檔案即可\n",
        "\n",
        "!gdown --id 1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe --output \"./Eileen_Legendary.txt\"\n",
        "\n",
        "# !wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe\n",
            "To: /content/Eileen_Legendary.txt\n",
            "100% 818k/818k [00:00<00:00, 139MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbvzh_9_Tz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27000ae2-cfc5-4963-eef2-9dcdaef7b0e2"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"/content/史蒂芬．金《蕭山克的救贖》.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"史蒂芬．金《蕭山克的救贖》共有{book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "史蒂芬．金《蕭山克的救贖》共有71242 字詞\n",
            "包含了 2464 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一六年四月一日版》\n",
            "《好讀書櫃》經典版\n",
            "第一部分\n",
            "我相信我說過，監獄裡每個犯人都聲稱自己無辜。他們只是碰上了鐵石心腸的法官、無能的律師、警察的誣告，而成為受害者，再不然就是運氣實在太壞了。儘管他們手按《聖經》宣誓，但卻口是心非，像電視布道家那樣信口開河而已。大多數囚犯都不是什麼好人，無論對自己或對別人，都沒什麼好處，他們最大的不幸，就是被生到這世上來。\n",
            "※※※\n",
            "第一章\n",
            "我猜美國每個州立監獄和聯邦監獄裡，都有像我這樣的一號人物，不論什麼東西，我都能為你弄到手。無論是高級香菸或大麻（如果你偏好此道的話），或弄瓶白蘭地來慶祝兒子或女兒高中畢業，總之差不多任何東西……我的意思是說，只要在合理範圍內，我是有求必應；可是很多情況不一定都合情合理的。\n",
            "我剛滿二十歲就來到蕭山克監獄。在這個快樂小家庭中，我是少數肯痛痛快快承認自己幹了什麼的人。我犯了謀殺罪。我為大我三歲的太太投保了一筆數目龐大的壽險，然後在她父親送我們的結婚禮物──一輛雪佛蘭轎車的剎車上動了手腳。一切都正如我的計劃，只是沒料到她在半路上停下來載了鄰居太太和她的小兒子，他們正一起下城堡山進城去。結果煞車失靈，車速越來越快，衝過路邊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT90O679Fe0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c471f965-843e-4652-a94e-4be92e78a16c"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_uP5gOVIy2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a4ac38-94fc-446f-9dd6-d145ac200b32"
      },
      "source": [
        "print(f\"原本張愛玲散文集共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本張愛玲散文集共有 71242 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘66689個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LP0BwFDAmcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047571e5-3d72-4c2f-d694-182adea7f8d3"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '一', '六', '年', '四', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經', '典', '版', '\\n', '第', '一', '部', '分', '\\n', '我', '相', '信', '我', '說', '過', '，', '監', '獄', '裡', '每', '個']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{897, 773, 907, 780, 913, 792, 921, 668, 927, 800, 936, 942, 944, 820, 310, 951, 952, 955, 829, 65, 708, 454, 840, 848, 721, 722, 723, 867, 612, 875, 762}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aDyjJymDmVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1dd5d9-c7b7-4ae5-f526-78e408098645"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[944 721 848 951 820 921 840 780 951 722 454 723 944 721 907 310 762  65\n",
            " 723 875 612], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '一', '六', '年', '四', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經', '典']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[454 944 773 951 708 800 944 952 668 792 952 936 927 955 867 913 897 829\n",
            " 942 838 941], shape=(21,), dtype=int32)\n",
            "['版', '\\n', '第', '一', '部', '分', '\\n', '我', '相', '信', '我', '說', '過', '，', '監', '獄', '裡', '每', '個', '犯', '人']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhFC16MdLONw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4970f3-5a0a-41fa-e7d3-506fb3982f02"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnJ4Bdj2gZ1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27ed1f2-fbec-478a-f8b7-74fcebc77b63"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['\\n', '《', '二', '一', '六', '年', '四', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經']\n",
            "Target: ['《', '二', '一', '六', '年', '四', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經', '典']\n",
            "--------------------------------------------------\n",
            "Input : [944 721 848 951 820 921 840 780 951 722 454 723 944 721 907 310 762  65\n",
            " 723 875]\n",
            "Target: [721 848 951 820 921 840 780 951 722 454 723 944 721 907 310 762  65 723\n",
            " 875 612]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNivSh2Igr2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5582aa0-5de8-42c6-82d2-200a7dce049a"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkRcSZAHnxlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d4b0f3-3f7c-4805-906b-61c853b3ae61"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 512)         489472    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 956)         1958844   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,302,012\n",
            "Trainable params: 128,302,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKiszF5doFGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351ae271-dbac-4d13-ee01-63ff0eb5e87b"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 956)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsN6Zz4NReV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e4bdb5-2eef-4c92-9e49-3c9e21e2dd68"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "「所有的地質學都是在究壓力。」\n",
            "當然，還\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "專抗扔扔扔扔扔扔雕雕男雕雕雕岩岩造造造造\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IW5xiiMpJhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc5c9f5-6a87-421c-9d6c-85a5b5baf4d8"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "49/49 [==============================] - 17s 307ms/step - loss: 6.2627\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 16s 319ms/step - loss: 5.7757\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 16s 327ms/step - loss: 5.4563\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 16s 322ms/step - loss: 5.1574\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 4.8707\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 16s 315ms/step - loss: 4.5819\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 16s 314ms/step - loss: 4.2975\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 16s 322ms/step - loss: 3.9819\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 16s 325ms/step - loss: 3.6037\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 16s 321ms/step - loss: 3.1115\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 2.4892\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 1.7962\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 1.1442\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 16s 320ms/step - loss: 0.6891\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 16s 316ms/step - loss: 0.4650\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 0.3632\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 15s 312ms/step - loss: 0.3052\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 15s 314ms/step - loss: 0.2689\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.2470\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 15s 308ms/step - loss: 0.2334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6e0f014b-3080-47c6-ad28-d853e9c242f2"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3elbMNg4z4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484ea24a-be43-49f7-fd69-5633f4c1294e"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "「所有的地質學都是在究壓力。」\n",
            "當然，還\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "我有的地質學都是在究壓力。」\n",
            "當然，還有\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61a57cc-d961-4ed9-c8a8-c08d0e42f56c"
      },
      "source": [
        "init_seq = \"諾頓\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "諾頓做髒事，也繼續管理圖書館，所以從外表看看在他走了。\n",
            "「我說，」我說，「我是安迪，你知道。\n",
            "「他們說到這兒子，我真的到了。」\n",
            "「那是你的見子，」他說，「你是跟你的事法，」他說，「雷德，」他說，「你是怎麼辦法的。」\n",
            "「我想我只知道。」\n",
            "「我知道，」安迪說，「不過你看起來也不像特別會別。別人，我可以把太太情況，但是我的朋友吉米幫我弄的，他是在我上訴被被關的那個部分，大門已厭有三十個，」他的「「」。\n",
            "「我們打開《聖經》第二十三篇一起讀吧」的聲音。\n",
            "「你是怎麼辦到的？」安迪問，「你為什麼？」\n",
            "「我想你不知道。」\n",
            "「我知道，」安迪說，「我們打定一定都不留過。我問他是怎麼出事的。他們到這些經經的監獄，而且在我的時候，你過得很好。\n",
            "你的朋友\n",
            "我從來不曾殺過那個傢伙，他在「大年一樣，都會放給你的日子。」\n",
            "「你是說，你先射殺了昆丁？」\n",
            "「不管，」他說，「真是一報還一報。而打，在他們發現的表情都下，安迪長步的。「我們打開了，但是……」\n",
            "「我已經幫了你一個忙，」諾頓平靜道，「但我知道這兒至少。」\n",
            "「我知道，」安迪說，「不過你看起來也不像特別會別。別人，我可以把太太情況，但是我的朋友吉米幫我弄的，他是在我上訴被"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8180c036-8c10-49f8-e1d1-df0709e281d4"
      },
      "source": [
        "init_seq = \"諾頓\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "諾頓做髒事，也繼續管理圖書館，所以從外表看看看了他會走了，因為他在監獄的醫務室傷。\n",
            "這些東西並非免費的，有些東西代價不。但我不確定這樣是否。我想他也很喜歡。」\n",
            "「我想你也是受你的。」\n",
            "「那麼你聽到他告訴我，他每次都聽得這麼事，我總告訴他：他一直奮靜，沒有人會費掉，但是他們走過的最冷開，否則是死紀的，但是我知道那天晚上，當的暗天色逐漸變得黑，黑得像六點人的腦袋中，不過再上面是我的名字，是安迪整點時間，我才想到他是個東西。\n",
            "「星，雷德，我知道，這是在監獄裡過了大半子的結果。在牢裡，我就有五個月，那個老家的人仍然變得，我的眼睛，我就會把它斷。你可以把子插下子的全。\n",
            "現在我要告訴你一九五〇年五月中發生的事情。當時我們已經了一個叫鎮的名字，大部分我們的大概只是個小鏡子。\n",
            "「你知道，」他說，「你是說，你會想起你的。」\n",
            "「這麼你聽到他告訴我，他的老婆總是對他們為「話的，或許是……」\n",
            "「我知道，」安迪說，「不過你看起來也不像特別會別。別人，我可以把太太情況，但是我的朋友吉米幫我弄的，他是在我上訴被被關的那個部分，大門已厭壓了，他們不能隨有五百元，此後十年中，圖書館每年都收得他的。\n",
            "我記了，當年我的朋友吉米"
          ]
        }
      ]
    }
  ]
}